---
date: "2024-04-25T13:54:15Z"
title: "2024-04-25"
draft: false
tags:
- fine-tuning
- gpt-3.5-turbo
---

I read this interesting [article](https://gajus.com/blog/fine-tuning-openai-models) by Gajus about finetuning gpt-3.5-turbo.
It was quite similar to [my experience]({{< ref "posts/2024/fine-tuning-connections.md" >}}) fine tuning a model to play Connections.
A helpful takeaway was that after finetuning the model, you shouldn't need to include system prompt in future model inference, so you can save on token cost.
I also liked the suggestion to use a database to store training data.
I had also been wrangling jsonl files.

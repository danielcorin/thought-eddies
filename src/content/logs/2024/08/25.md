---
date: "2024-08-25T09:40:23Z"
title: "2024-08-25"
draft: false
---

I tried [Townie](https://www.val.town/townie).
As has become tradition, I tried to build a writing editor for myself.
Townie got a simple version of this working with the ability to send a highlighted selection of text to the backend and run it through a model along with a prompt.
This experience was relatively basic, using a textarea and a popup.
From here, I got Townie to add the ability to show diffs between the model proposal and original text.
It was able to do this for the selected text using CSS in a straightforward manner.
I wanted to support multiple line diffs and diffs across multiple sections of the file.
I suggested we use an open source text editor.
At this point, things started to break.
The app stopped rendering and I wasn't able to prompt it into resolving the issue.
I did manage to get it to revert (fixing forward) to a state where the app rendered again.
However, the LLM-completion hotkey was broken.

These model-assisted code generation tools are quite powerful, but in my opinion, they require multiple interaction UX options for the end user.
High-level directives through a chat don't seem to be enough to build complex applications and debugging skills are necessary if you want to integrate or adopt some code and the model is failing to do it as instructed.
